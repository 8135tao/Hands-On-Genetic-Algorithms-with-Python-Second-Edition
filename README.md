# Hands-On-Genetic-Algorithms-with-Python-Second-Edition
Hands-On Genetic Algorithms with Python, Second Edition, published by Packt

## Installing Dependencies

### Prerequisites
* The recommended Python version for this project is **3.12**. If you have a different version of Python installed, you can find this version [here] (https://www.python.org/downloads/release/python-3123/) and download the file that matches your operating system.
* For Windows users, 
  * **Microsoft Visual C++ 14.0** or greater may be required. If prompted, follow the installation instructions available [here](https://www.scivision.dev/python-windows-visual-c-14-required).
  * Alternatively, you can set up a Linux environment on Windows using the Windows Subsystem for Linux (WSL), as detailed [here](https://learn.microsoft.com/en-us/windows/wsl/setup/environment).


### Virtual Environment
#### Creation
It is recommended to install the required dependencies within a **virtual environment**. To create one, follow these steps:
```bash
cd path/to/repository
python -m venv venv
```

> **NOTE:** 
If you have more than one version of Python installed in your system, you can specify the version to be used in the virual environment when creating it:
> - **Windows:** `py -3.12 -m venv venv`
> - **macOS and Linux:** `python3.12 -m venv venv`


#### Activation
Activate the virtual environment using the appropriate command for your operating system:

- **Windows:** `venv\Scripts\activate`
- **macOS and Linux:** `source venv/bin/activate`

#### Installing dependencies

After activation, install the dependencies with:
```bash
pip install -r requirements.txt
```

## Chapter 3: Using the DEAP Framework
Explore the 'OneMax' problem while introducing the basics of genetic algorithms using the DEAP framework.
- `chapter_03/01_OneMax_long.py`: Solve the OneMax problem from scratch.
- `chapter_03/02_OneMax_short.py`: Solve the OneMax problem using the DEAP framework.
- `chapter_03/03_OneMax_short_hof.py`: Solve the OneMax problem while demonstrating the use of DEAP's Hall-of-Fame (HOF) feature.

## Chapter 4: Combinatorial Optimization
Learn how genetic algorithms can be applied in combinatorial optimization, covering topics like genotype-to-phenotype mapping, and exploration versus exploitation.
- `chapter_04/01_solve_knapsack.py`: Solve the Knapsack-01 problem.
- `chapter_04/02_solve_tsp_first_attempt.py`: Approach the Traveling Salesman Problem (TSP).
- `chapter_04/03_solve_tsp.py`: Improve TSP solution by utilizing the Elitist Approach.
- `chapter_04/04_solve_vrp.py`: Solve the Vehicle Routing Problem (VRP).

## Chapter 5: Constraint Satisfaction
Explore the use of genetic algorithms for solving constraint satisfaction problems, understanding hard and soft constraints, and their integration into solutions.
- `chapter_05/01_solve_n_queens.py`: Solve the N-Queens problem.
- `chapter_05/02_solve_nurses.py`: Address a nurse shift scheduling problem.
- `chapter_05/03_solve_graphs.py`: Tackle the graph coloring problem.

## Chapter 6: Optimizing Continuous Functions
Discover how to solve continuous search-space optimization problems using genetic algorithms, learn about niching and sharing for finding multiple solutions, and handle constraints.
- `chapter_06/01_optimize_eggholder.py`: Optimize the EggHolder function.
- `chapter_06/02_optimize_himmelblau.py`: Optimize Himmelblau's function.
- `chapter_06/03_optimize_himmelblau_sharing.py`: Find all potential solutions for Himmelblau's function using niching and sharing.
- `chapter_06/04_optimize_simionescu.py`: Perform constrained optimization with Simionescu's function.
- `chapter_06/05_optimize_simionescu_second.py`: Find multiple solutions for Simionescu's function using sequential niching.

## Chapter 7: Enhancing Machine Learning Models Using Feature Selection
Learn about supervised machine learning models and how genetic algorithms can be used to improve their performance by selecting the best subset of features from the provided input data.
- `chapter_07/01_solve_friedman.py`: Isolate the genuine features that are generated by the Friedman-1 Test regression problem.
- `chapter_07/02_solve_zoo.py`: Improve the classification results of the Zoo dataset by identifying the best features for the task.

## Chapter 8: Hyperparameter Tuning of Machine Learning Models
Find out how genetic algorithms can be used to improve the performance of supervised machine learning models by tuning the hyperparameters of the models.
- `chapter_08/01_hyperparameter_tuning_grid.py`: Enhance the performance of a classifier using a genetic algorithm-driven hyperparameter grid search.
- `chapter_08/02_hyperparameter_tuning_genetic.py`: Enhance the performance of a classifier using a direct genetic algorithm approach for hyperparameter tuning.

## Chapter 9: Architecture Optimization of Deep Learning Networks
Explore how genetic algorithms can be used to improve the performance of artificial neural network-based models by optimizing the network architecture of these models as well as their hyperparameters.
- `chapter_09/01_optimize_mlp_layers.py`: Optimize the network architecture of a neural network classifier.
- `chapter_09/02_optimize_mlp_hyperparameters.py`: Jointly optimize the hyperparameters and the network architecture of a neural network classifier.

## Chapter 10: Reinforcement Learning with Genetic Algorithms
Learn how genetic algorithms can be applied to reinforcement learning by solving two benchmark environments from the Gymnasium (formerly OpenAI Gym) toolkit.
- `chapter_10/01_solve_mountain_car.py`: Solve the Gymnasium *MountainCar* environment (then run `mountain_car.py` to view the solution).
- `chapter_10/02_solve_cart_pole.py`: Solve the Gymnasium *CartPole* environment (then run `cart_pole.py` to view the solution).

## Chapter 11: Natural Language Processing
Explore how genetic algorithms can enhance the performance of Natural Language Processing (NLP) tasks while offering insights into their underlying mechanisms.
- `chapter_11/01_find_mystery_word.py`: Play a *Semantle*-like Mystery-Word game, and find the mystery word.
- `chapter_11/02_solve_newsgroups.py`: Identify a compact yet effective subset of features when using n-grams for document classification.

## Chapter 12: Explainable AI, Causality and Counterfactuals with Genetic Algorithms
Explore the application of genetic algorithms for generating 'what-if' scenarios, providing valuable insights into the analysis of datasets and associated machine learning models, while enabling actionable insights that help achieve desired outcomes.
- `chapter_12/01_counterfactual_search.py`: Apply a *counterfactual* analysis to the *German Credit Risk* dataset and discover valuable insights.
- `chapter_12/02_counterfactual_search.py`: Apply further analysis to the dataset to answer additional questions.

## Chapter 13: Accelerating Genetic Algorithms: The Power of Concurrency 
Learn how to use multiprocessing to boost the performance of genetic algorithms. 
- `chapter_13/01_one_max_start.py`: Use a reduced version of the OneMax problem to serve as a baseline.
- `chapter_13/02_one_max_busy.py`: Modify the baseline to simulate computational intensity, resulting in extended run time.
- `chapter_13/03_one_max_pool.py`: Utilize the `multiprocessing.Pool` module to parallelize and accelerate the genetic algorithm operation.
- `chapter_13/04_one_max_pool_loop.py`: Employ the `multiprocessing.Pool` module with a varying number of processes to examine the effect on performance.
- `chapter_13/05_one_max_scoop.py`: Utilize the `Scoop` library as an alternative method to parallelize and accelerate the genetic algorithm operation.

## Chapter 14: Beyond Local Resources: Scaling Genetic Algorithms in the Cloud
Restructure the genetic algorithm into a **client-server model**, where the client employs asynchronous I/O, and the server manages fitness function calculations. The server component is then deployed to the cloud using AWS Lambda.  

### Client side
- `chapter_14/01_one_max_client.py`: Implement the client part of the genetic algorithm.
- `chapter_14/02_one_max_async_client.py`: Convert the client implementation to an asynchronous client.

### Server side
- `chapter_14/server/fitness_evaluator.py`: Implement the server part of the genetic algorithm as a Flask application.
- `chapter_14/server/fitness_evaluator_waitress.py`: Implement the server part of the genetic algorithm as a Flask application within a standalone `Waitress` server.
- 
#### Server Environment
To use the server files, it is necessary to create a separate virtual environment. The dependencies required for this environment are listed in the file `chapter_14/server/requirements-server.txt`.

## Chapter 15: Evolutionary Image Reconstruction with Genetic Algorithms 
Experiment with image processing and create a reconstruction of the Mona Lisa with a set of semi-transparent polygons. 
- `chapter_15/01_reconstruct_with_polygons.py`: Reconstruct the Mona Lisa using semi-transparent triangles.
- `chapter_15/02_reconstruct_with_polygons_blur.py`: Experiment with an alternative fitness evaluation method to reconstruct the image using a minimal count of triangles.

## Chapter 16: Other Evolutionary and Bio-Inspired Computation Techniques 
Discover several new problem-solving and optimization techniques related to genetic algorithms.
- `chapter_16/01_gp_even_parity.py`: Solve the *even parity* problem using **genetic programming**.
- `chapter_16/02_gp_even_parity_reduced.py`: Simplify the *even parity* solution by adding a constraint.
- `chapter_16/03_neat_even_parity.py`: Solve the *even parity* problem using **NeuroEvolution of Augmenting Topologies (NEAT)**.
- `chapter_16/04_pso_himmelblau.py`: Optimize Himmelblau's function using **particle swarm optimization**.
  



